{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WH1Pr4KQlCh"
   },
   "source": [
    "### Build a DNN using Keras with `RELU` and `ADAM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbvI8LqlQlCl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPW-a-qYQlCp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74cQBsi5QlCw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Collect Fashion mnist data from tf.keras.datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVWy0oDTr2Kj"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training examples:  60000\n"
     ]
    }
   ],
   "source": [
    "print('Number of Training examples: ', trainX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the output to categorical variables\n",
    "\n",
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no7aWYZyQlC1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjNrRTdoQlC5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the Sequential Model\n",
    "model=tf.keras.models.Sequential()\n",
    "#Reshape the data from 28X28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28)))\n",
    "#Normalizing the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 1st hidden layer\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "#Add 2nd hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDJ9DHVNQlC7"
   },
   "source": [
    "#### Initialize model, reshape & normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "pCDQs_g1QlC8",
    "outputId": "e854b4d2-903a-4515-c21b-bd6a6e4fe2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Done above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 181,246\n",
      "Trainable params: 179,678\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Checking for what is the architecture of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 0.2818 - acc: 0.9163 - val_loss: 0.1914 - val_acc: 0.9526\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.1329 - acc: 0.9588 - val_loss: 0.1586 - val_acc: 0.9623\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0954 - acc: 0.9706 - val_loss: 0.1584 - val_acc: 0.9672\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.0758 - acc: 0.9763 - val_loss: 0.1359 - val_acc: 0.9706\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0628 - acc: 0.9800 - val_loss: 0.1479 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 13s 212us/sample - loss: 0.0511 - acc: 0.9838 - val_loss: 0.1634 - val_acc: 0.9697\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.0448 - acc: 0.9855 - val_loss: 0.1523 - val_acc: 0.9695\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.0374 - acc: 0.9877 - val_loss: 0.1480 - val_acc: 0.9705\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 13s 214us/sample - loss: 0.0332 - acc: 0.9890 - val_loss: 0.1508 - val_acc: 0.9708\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0296 - acc: 0.9905 - val_loss: 0.1543 - val_acc: 0.9715\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 0.0264 - acc: 0.9912 - val_loss: 0.1557 - val_acc: 0.9717\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 0.0231 - acc: 0.9924 - val_loss: 0.1448 - val_acc: 0.9725\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 14s 237us/sample - loss: 0.0219 - acc: 0.9929 - val_loss: 0.1493 - val_acc: 0.9718\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 0.0199 - acc: 0.9934 - val_loss: 0.1643 - val_acc: 0.9704\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 14s 228us/sample - loss: 0.0168 - acc: 0.9947 - val_loss: 0.1479 - val_acc: 0.9729\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.0157 - acc: 0.9948 - val_loss: 0.1606 - val_acc: 0.9714\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 0.0156 - acc: 0.9953 - val_loss: 0.1587 - val_acc: 0.9722\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.0129 - acc: 0.9960 - val_loss: 0.1676 - val_acc: 0.9726\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.1789 - val_acc: 0.9718\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 12s 197us/sample - loss: 0.0131 - acc: 0.9962 - val_loss: 0.1610 - val_acc: 0.9738\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.0116 - acc: 0.9965 - val_loss: 0.1639 - val_acc: 0.9725\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 0.0111 - acc: 0.9968 - val_loss: 0.1699 - val_acc: 0.9731\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 0.0096 - acc: 0.9970 - val_loss: 0.1721 - val_acc: 0.9729\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.1685 - val_acc: 0.9734\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 0.0093 - acc: 0.9972 - val_loss: 0.1694 - val_acc: 0.9738: 0.0094 - acc:\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 12s 193us/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.1684 - val_acc: 0.9723\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0073 - acc: 0.9980 - val_loss: 0.1812 - val_acc: 0.9718\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 0.1685 - val_acc: 0.9739\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 11s 180us/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.1659 - val_acc: 0.9740\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 11s 191us/sample - loss: 0.0073 - acc: 0.9977 - val_loss: 0.1658 - val_acc: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22ee31016d8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBGwTTilQlDD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "IXbfpfOzQlDF",
    "outputId": "f46a2e3a-2634-4e9e-88bd-57bb8de1ff0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Added the layers in the architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Initializing the Sequential Model\n",
    "model=tf.keras.models.Sequential()\n",
    "#Reshape the data from 28X28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28)))\n",
    "#Normalizing the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Adding the 1st hidden layer\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "#Add 2nd hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "#Adding the dropout layer now, as it should be closer to the output than to the input as we\n",
    "#need the architecture to be created first and then we would atleast have a shape for the \n",
    "#pattern that our model has created and we would be in a position to droput certain neurons\n",
    "model.add(tf.keras.layers.Dropout(0.3,input_shape=(784,)))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 181,246\n",
      "Trainable params: 179,678\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I8f5otcQlDJ"
   },
   "source": [
    "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 0.3585 - acc: 0.8892 - val_loss: 0.1946 - val_acc: 0.9486\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 0.1821 - acc: 0.9454 - val_loss: 0.1623 - val_acc: 0.9592\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.1380 - acc: 0.9583 - val_loss: 0.1559 - val_acc: 0.9655\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 12s 199us/sample - loss: 0.1133 - acc: 0.9650 - val_loss: 0.1385 - val_acc: 0.9677\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 12s 198us/sample - loss: 0.0975 - acc: 0.9693 - val_loss: 0.1493 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0854 - acc: 0.9731 - val_loss: 0.1302 - val_acc: 0.9701\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 12s 198us/sample - loss: 0.0750 - acc: 0.9765 - val_loss: 0.1406 - val_acc: 0.9704\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.0679 - acc: 0.9783 - val_loss: 0.1436 - val_acc: 0.9714\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 0.0622 - acc: 0.9801 - val_loss: 0.1327 - val_acc: 0.9709\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.0554 - acc: 0.9822 - val_loss: 0.1285 - val_acc: 0.9731\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.0509 - acc: 0.9835 - val_loss: 0.1308 - val_acc: 0.9732\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.0466 - acc: 0.9847 - val_loss: 0.1264 - val_acc: 0.9749\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.0446 - acc: 0.9857 - val_loss: 0.1253 - val_acc: 0.9760\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 0.0408 - acc: 0.9862 - val_loss: 0.1352 - val_acc: 0.9751\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 0.0405 - acc: 0.9870 - val_loss: 0.1229 - val_acc: 0.9768\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 0.0371 - acc: 0.9879 - val_loss: 0.1317 - val_acc: 0.9751\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 0.0347 - acc: 0.9884 - val_loss: 0.1248 - val_acc: 0.9758\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 0.0318 - acc: 0.9892 - val_loss: 0.1285 - val_acc: 0.9742\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.0308 - acc: 0.9896 - val_loss: 0.1362 - val_acc: 0.9752\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.0295 - acc: 0.9900 - val_loss: 0.1429 - val_acc: 0.9745\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.0276 - acc: 0.9909 - val_loss: 0.1367 - val_acc: 0.9761\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 0.0263 - acc: 0.9911 - val_loss: 0.1370 - val_acc: 0.9763\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.0252 - acc: 0.9916 - val_loss: 0.1237 - val_acc: 0.9763\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0238 - acc: 0.9921 - val_loss: 0.1324 - val_acc: 0.9767\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 12s 197us/sample - loss: 0.0227 - acc: 0.9922 - val_loss: 0.1396 - val_acc: 0.9744\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0219 - acc: 0.9926 - val_loss: 0.1452 - val_acc: 0.9745\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 12s 199us/sample - loss: 0.0204 - acc: 0.9928 - val_loss: 0.1473 - val_acc: 0.9758\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 0.0198 - acc: 0.9936 - val_loss: 0.1493 - val_acc: 0.9753\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 0.0202 - acc: 0.9932 - val_loss: 0.1355 - val_acc: 0.9759 loss: 0.0198 - \n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 12s 199us/sample - loss: 0.0201 - acc: 0.9929 - val_loss: 0.1493 - val_acc: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22ee73c1f28>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MNIST.h1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "updated_R7_ExternalLab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
