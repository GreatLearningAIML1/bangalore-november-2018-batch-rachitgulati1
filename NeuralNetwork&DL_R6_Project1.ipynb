{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"RowNumber\",\"CustomerId\",\"Surname\",\"Geography\",\"Gender\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  \n",
       "0               1        101348.88       1  \n",
       "1               1        112542.58       0  \n",
       "2               0        113931.57       1  \n",
       "3               0         93826.63       0  \n",
       "4               1         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ind=df.drop(columns=\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dep=df[[\"Exited\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_ind.shape)\n",
    "print(y_dep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 67% for train and 30% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ind, y_dep, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/250\n",
      "7000/7000 [==============================] - 3s 425us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 2/250\n",
      "7000/7000 [==============================] - 2s 261us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 3/250\n",
      "7000/7000 [==============================] - 2s 295us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 4/250\n",
      "7000/7000 [==============================] - 2s 309us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 5/250\n",
      "7000/7000 [==============================] - 2s 289us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 6/250\n",
      "7000/7000 [==============================] - 2s 302us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 7/250\n",
      "7000/7000 [==============================] - 2s 345us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 8/250\n",
      "7000/7000 [==============================] - 2s 348us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 9/250\n",
      "7000/7000 [==============================] - 2s 323us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 10/250\n",
      "7000/7000 [==============================] - 2s 308us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 11/250\n",
      "7000/7000 [==============================] - 2s 300us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 12/250\n",
      "7000/7000 [==============================] - 2s 272us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 13/250\n",
      "7000/7000 [==============================] - 2s 286us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 14/250\n",
      "7000/7000 [==============================] - 2s 286us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 15/250\n",
      "7000/7000 [==============================] - 2s 287us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 16/250\n",
      "7000/7000 [==============================] - 2s 275us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 17/250\n",
      "7000/7000 [==============================] - 2s 270us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 18/250\n",
      "7000/7000 [==============================] - 2s 267us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 19/250\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 20/250\n",
      "7000/7000 [==============================] - 3s 362us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 21/250\n",
      "7000/7000 [==============================] - 2s 326us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 22/250\n",
      "7000/7000 [==============================] - 2s 346us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 23/250\n",
      "7000/7000 [==============================] - 2s 336us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 24/250\n",
      "7000/7000 [==============================] - 2s 270us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 25/250\n",
      "7000/7000 [==============================] - 2s 271us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 26/250\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 27/250\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 28/250\n",
      "7000/7000 [==============================] - 2s 315us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 29/250\n",
      "7000/7000 [==============================] - 2s 277us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 30/250\n",
      "7000/7000 [==============================] - 2s 272us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 31/250\n",
      "7000/7000 [==============================] - 2s 273us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 32/250\n",
      "7000/7000 [==============================] - 2s 272us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 33/250\n",
      "7000/7000 [==============================] - 2s 276us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 34/250\n",
      "7000/7000 [==============================] - 2s 308us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 35/250\n",
      "7000/7000 [==============================] - 2s 287us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 36/250\n",
      "7000/7000 [==============================] - 2s 273us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 37/250\n",
      "7000/7000 [==============================] - 2s 276us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 38/250\n",
      "7000/7000 [==============================] - 2s 260us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 39/250\n",
      "7000/7000 [==============================] - 2s 273us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 40/250\n",
      "7000/7000 [==============================] - 2s 272us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 41/250\n",
      "7000/7000 [==============================] - 2s 304us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 42/250\n",
      "7000/7000 [==============================] - 3s 380us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 43/250\n",
      "7000/7000 [==============================] - 3s 374us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 44/250\n",
      "7000/7000 [==============================] - 2s 326us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 45/250\n",
      "7000/7000 [==============================] - 2s 318us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 46/250\n",
      "7000/7000 [==============================] - 2s 327us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 47/250\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 48/250\n",
      "7000/7000 [==============================] - 3s 435us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 49/250\n",
      "7000/7000 [==============================] - 3s 359us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 50/250\n",
      "7000/7000 [==============================] - 2s 315us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 51/250\n",
      "7000/7000 [==============================] - 2s 316us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 52/250\n",
      "7000/7000 [==============================] - 2s 295us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 53/250\n",
      "7000/7000 [==============================] - 2s 293us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 54/250\n",
      "7000/7000 [==============================] - 2s 270us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 55/250\n",
      "7000/7000 [==============================] - 2s 274us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 56/250\n",
      "7000/7000 [==============================] - 2s 347us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 57/250\n",
      "7000/7000 [==============================] - 2s 299us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 58/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 2s 279us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 59/250\n",
      "7000/7000 [==============================] - 2s 283us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 60/250\n",
      "7000/7000 [==============================] - 2s 278us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 61/250\n",
      "7000/7000 [==============================] - 2s 281us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 62/250\n",
      "7000/7000 [==============================] - 2s 282us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 63/250\n",
      "7000/7000 [==============================] - 2s 330us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 64/250\n",
      "7000/7000 [==============================] - 3s 370us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 65/250\n",
      "7000/7000 [==============================] - 2s 308us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 66/250\n",
      "7000/7000 [==============================] - 2s 304us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 67/250\n",
      "7000/7000 [==============================] - 2s 303us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 68/250\n",
      "7000/7000 [==============================] - 2s 311us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 69/250\n",
      "7000/7000 [==============================] - 2s 299us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 70/250\n",
      "7000/7000 [==============================] - 3s 402us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 71/250\n",
      "7000/7000 [==============================] - 3s 452us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 72/250\n",
      "7000/7000 [==============================] - 3s 370us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 73/250\n",
      "7000/7000 [==============================] - 2s 274us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 74/250\n",
      "7000/7000 [==============================] - 2s 346us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 75/250\n",
      "7000/7000 [==============================] - 2s 336us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 76/250\n",
      "7000/7000 [==============================] - 2s 282us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020s - loss: 3.3187 - acc: 0\n",
      "Epoch 77/250\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 78/250\n",
      "7000/7000 [==============================] - 2s 257us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 79/250\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 80/250\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 81/250\n",
      "7000/7000 [==============================] - 2s 273us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 82/250\n",
      "7000/7000 [==============================] - 2s 281us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020loss: 3.3\n",
      "Epoch 83/250\n",
      "7000/7000 [==============================] - 2s 269us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 84/250\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 85/250\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 86/250\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 87/250\n",
      "7000/7000 [==============================] - 2s 246us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 88/250\n",
      "7000/7000 [==============================] - 2s 247us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 89/250\n",
      "7000/7000 [==============================] - 2s 248us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020 - loss: 3.3312 - acc: 0.79\n",
      "Epoch 90/250\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 91/250\n",
      "7000/7000 [==============================] - 2s 247us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 92/250\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 93/250\n",
      "7000/7000 [==============================] - 2s 249us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 94/250\n",
      "7000/7000 [==============================] - 2s 292us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 95/250\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 96/250\n",
      "7000/7000 [==============================] - 2s 304us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 97/250\n",
      "7000/7000 [==============================] - 3s 396us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 98/250\n",
      "7000/7000 [==============================] - 2s 279us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 99/250\n",
      "7000/7000 [==============================] - 2s 277us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 100/250\n",
      "7000/7000 [==============================] - 2s 352us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 101/250\n",
      "7000/7000 [==============================] - 2s 280us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 102/250\n",
      "7000/7000 [==============================] - 2s 278us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 103/250\n",
      "7000/7000 [==============================] - 2s 293us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 104/250\n",
      "7000/7000 [==============================] - 2s 311us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 105/250\n",
      "7000/7000 [==============================] - 2s 316us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 106/250\n",
      "7000/7000 [==============================] - 2s 276us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 107/250\n",
      "7000/7000 [==============================] - 2s 281us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 108/250\n",
      "7000/7000 [==============================] - 2s 287us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 109/250\n",
      "7000/7000 [==============================] - 2s 299us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 110/250\n",
      "7000/7000 [==============================] - 3s 409us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 111/250\n",
      "7000/7000 [==============================] - 2s 329us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 112/250\n",
      "7000/7000 [==============================] - 2s 297us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 113/250\n",
      "7000/7000 [==============================] - 2s 295us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 114/250\n",
      "7000/7000 [==============================] - 2s 300us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 115/250\n",
      "7000/7000 [==============================] - 3s 398us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 116/250\n",
      "7000/7000 [==============================] - 2s 316us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/250\n",
      "7000/7000 [==============================] - 3s 375us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 118/250\n",
      "7000/7000 [==============================] - 2s 314us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020- loss: 3.3069 - acc: 0.\n",
      "Epoch 119/250\n",
      "7000/7000 [==============================] - 2s 350us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 120/250\n",
      "7000/7000 [==============================] - 2s 277us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020.3012 - acc: 0.7\n",
      "Epoch 121/250\n",
      "7000/7000 [==============================] - 2s 300us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 122/250\n",
      "7000/7000 [==============================] - 3s 366us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 123/250\n",
      "7000/7000 [==============================] - 3s 396us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 124/250\n",
      "7000/7000 [==============================] - 2s 353us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 125/250\n",
      "7000/7000 [==============================] - 3s 376us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 126/250\n",
      "7000/7000 [==============================] - 3s 379us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 127/250\n",
      "7000/7000 [==============================] - 2s 353us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 128/250\n",
      "7000/7000 [==============================] - 2s 343us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 129/250\n",
      "7000/7000 [==============================] - 4s 512us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 130/250\n",
      "7000/7000 [==============================] - 2s 323us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 131/250\n",
      "7000/7000 [==============================] - 2s 290us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 132/250\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 133/250\n",
      "7000/7000 [==============================] - 3s 427us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 134/250\n",
      "7000/7000 [==============================] - 2s 302us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 135/250\n",
      "7000/7000 [==============================] - 2s 353us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 136/250\n",
      "7000/7000 [==============================] - 2s 313us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 137/250\n",
      "7000/7000 [==============================] - 2s 328us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 138/250\n",
      "7000/7000 [==============================] - 3s 448us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 139/250\n",
      "7000/7000 [==============================] - 3s 454us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 140/250\n",
      "7000/7000 [==============================] - 3s 375us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 141/250\n",
      "7000/7000 [==============================] - 2s 354us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 142/250\n",
      "7000/7000 [==============================] - 2s 307us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 143/250\n",
      "7000/7000 [==============================] - 2s 296us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 144/250\n",
      "7000/7000 [==============================] - 2s 301us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 145/250\n",
      "7000/7000 [==============================] - 2s 334us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 146/250\n",
      "7000/7000 [==============================] - 2s 301us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 147/250\n",
      "7000/7000 [==============================] - 3s 359us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 148/250\n",
      "7000/7000 [==============================] - 2s 329us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 149/250\n",
      "7000/7000 [==============================] - 4s 556us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 150/250\n",
      "7000/7000 [==============================] - 4s 643us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 151/250\n",
      "7000/7000 [==============================] - 4s 545us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 152/250\n",
      "7000/7000 [==============================] - 3s 469us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 153/250\n",
      "7000/7000 [==============================] - 3s 458us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 154/250\n",
      "7000/7000 [==============================] - 4s 592us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 155/250\n",
      "7000/7000 [==============================] - 3s 449us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 156/250\n",
      "7000/7000 [==============================] - 3s 416us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 157/250\n",
      "7000/7000 [==============================] - 3s 425us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 158/250\n",
      "7000/7000 [==============================] - 3s 404us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 159/250\n",
      "7000/7000 [==============================] - 3s 417us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 160/250\n",
      "7000/7000 [==============================] - 3s 382us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 161/250\n",
      "7000/7000 [==============================] - 3s 409us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 162/250\n",
      "7000/7000 [==============================] - 4s 581us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 163/250\n",
      "7000/7000 [==============================] - 4s 502us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 164/250\n",
      "7000/7000 [==============================] - 3s 424us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 165/250\n",
      "7000/7000 [==============================] - 4s 505us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 166/250\n",
      "7000/7000 [==============================] - 3s 377us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 167/250\n",
      "7000/7000 [==============================] - 3s 438us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 168/250\n",
      "7000/7000 [==============================] - 3s 440us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 169/250\n",
      "7000/7000 [==============================] - 4s 573us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 170/250\n",
      "7000/7000 [==============================] - 3s 417us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 171/250\n",
      "7000/7000 [==============================] - 3s 416us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 172/250\n",
      "7000/7000 [==============================] - 3s 441us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 173/250\n",
      "7000/7000 [==============================] - 4s 538us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 174/250\n",
      "7000/7000 [==============================] - 4s 596us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 175/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 4s 501us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 176/250\n",
      "7000/7000 [==============================] - 3s 408us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 177/250\n",
      "7000/7000 [==============================] - 3s 408us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 178/250\n",
      "7000/7000 [==============================] - 3s 472us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 179/250\n",
      "7000/7000 [==============================] - 4s 501us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 180/250\n",
      "7000/7000 [==============================] - 4s 614us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 181/250\n",
      "7000/7000 [==============================] - 3s 399us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 182/250\n",
      "7000/7000 [==============================] - 2s 333us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 183/250\n",
      "7000/7000 [==============================] - 2s 319us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 184/250\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 185/250\n",
      "7000/7000 [==============================] - 3s 467us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 186/250\n",
      "7000/7000 [==============================] - 3s 400us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 187/250\n",
      "7000/7000 [==============================] - 2s 337us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 188/250\n",
      "7000/7000 [==============================] - 3s 442us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 189/250\n",
      "7000/7000 [==============================] - 3s 416us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 190/250\n",
      "7000/7000 [==============================] - 5s 658us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 191/250\n",
      "7000/7000 [==============================] - 4s 514us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 192/250\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 193/250\n",
      "7000/7000 [==============================] - 3s 381us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 194/250\n",
      "7000/7000 [==============================] - 3s 380us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 195/250\n",
      "7000/7000 [==============================] - 3s 378us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 196/250\n",
      "7000/7000 [==============================] - 3s 401us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 197/250\n",
      "7000/7000 [==============================] - 3s 457us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 198/250\n",
      "7000/7000 [==============================] - 3s 462us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 199/250\n",
      "7000/7000 [==============================] - 4s 538us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 200/250\n",
      "7000/7000 [==============================] - 3s 471us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 201/250\n",
      "7000/7000 [==============================] - 3s 412us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 202/250\n",
      "7000/7000 [==============================] - 3s 394us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 203/250\n",
      "7000/7000 [==============================] - 3s 489us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 204/250\n",
      "7000/7000 [==============================] - 4s 549us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 205/250\n",
      "7000/7000 [==============================] - 3s 446us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 206/250\n",
      "7000/7000 [==============================] - 3s 417us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 207/250\n",
      "7000/7000 [==============================] - 3s 369us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 208/250\n",
      "7000/7000 [==============================] - 3s 400us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 209/250\n",
      "7000/7000 [==============================] - 3s 472us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 210/250\n",
      "7000/7000 [==============================] - 3s 363us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 211/250\n",
      "7000/7000 [==============================] - 2s 300us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 212/250\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 213/250\n",
      "7000/7000 [==============================] - 3s 422us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 214/250\n",
      "7000/7000 [==============================] - 2s 333us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 215/250\n",
      "7000/7000 [==============================] - 2s 346us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 216/250\n",
      "7000/7000 [==============================] - 3s 445us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 217/250\n",
      "7000/7000 [==============================] - 3s 364us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 218/250\n",
      "7000/7000 [==============================] - 3s 405us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 219/250\n",
      "7000/7000 [==============================] - 3s 412us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 220/250\n",
      "7000/7000 [==============================] - 3s 416us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 221/250\n",
      "7000/7000 [==============================] - 2s 342us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 222/250\n",
      "7000/7000 [==============================] - 3s 359us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 223/250\n",
      "7000/7000 [==============================] - 2s 289us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 224/250\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 225/250\n",
      "7000/7000 [==============================] - 3s 379us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 226/250\n",
      "7000/7000 [==============================] - 3s 416us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 227/250\n",
      "7000/7000 [==============================] - 2s 337us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 228/250\n",
      "7000/7000 [==============================] - 2s 320us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 229/250\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 230/250\n",
      "7000/7000 [==============================] - 2s 331us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 231/250\n",
      "7000/7000 [==============================] - 3s 364us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 232/250\n",
      "7000/7000 [==============================] - 2s 304us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 233/250\n",
      "7000/7000 [==============================] - 3s 378us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 234/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 2s 322us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 235/250\n",
      "7000/7000 [==============================] - 3s 358us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 236/250\n",
      "7000/7000 [==============================] - 2s 305us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 237/250\n",
      "7000/7000 [==============================] - 2s 311us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 238/250\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 239/250\n",
      "7000/7000 [==============================] - 3s 433us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 240/250\n",
      "7000/7000 [==============================] - 2s 324us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 241/250\n",
      "7000/7000 [==============================] - 3s 400us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 242/250\n",
      "7000/7000 [==============================] - 2s 327us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 243/250\n",
      "7000/7000 [==============================] - 2s 290us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 244/250\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 245/250\n",
      "7000/7000 [==============================] - 2s 319us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 246/250\n",
      "7000/7000 [==============================] - 2s 311us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 247/250\n",
      "7000/7000 [==============================] - 2s 311us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 248/250\n",
      "7000/7000 [==============================] - 3s 445us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 249/250\n",
      "7000/7000 [==============================] - 3s 429us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n",
      "Epoch 250/250\n",
      "7000/7000 [==============================] - 3s 412us/step - loss: 3.3226 - acc: 0.7939 - val_loss: 3.1914 - val_acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca38b44550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=250,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now trying to normalize the data and trying a different flavour for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(12,input_dim=8,activation='relu'))\n",
    "#Normalize the data \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 5s 784us/sample - loss: 0.5222 - acc: 0.7871 - val_loss: 0.4956 - val_acc: 0.8020\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 4s 581us/sample - loss: 0.5107 - acc: 0.7939 - val_loss: 0.4948 - val_acc: 0.8020\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 4s 556us/sample - loss: 0.5078 - acc: 0.7939 - val_loss: 0.4967 - val_acc: 0.8020\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 3s 489us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4994 - val_acc: 0.8020\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 3s 497us/sample - loss: 0.5046 - acc: 0.7939 - val_loss: 0.4945 - val_acc: 0.8020\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 4s 514us/sample - loss: 0.5046 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 3s 492us/sample - loss: 0.5045 - acc: 0.7939 - val_loss: 0.4934 - val_acc: 0.8020\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 4s 542us/sample - loss: 0.5048 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 4s 562us/sample - loss: 0.5045 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 3s 441us/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 3s 493us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 5s 785us/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4934 - val_acc: 0.8020\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 5s 690us/sample - loss: 0.5036 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 4s 500us/sample - loss: 0.5042 - acc: 0.7939 - val_loss: 0.4924 - val_acc: 0.8020\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 4s 533us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 4s 524us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 4s 535us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 4s 594us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4930 - val_acc: 0.8020\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 3s 477us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4936 - val_acc: 0.8020\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 3s 461us/sample - loss: 0.5034 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 3s 467us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 3s 472us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 3s 478us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4936 - val_acc: 0.8020\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 3s 475us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 3s 479us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4925 - val_acc: 0.8020\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 3s 480us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.5009 - val_acc: 0.8020\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 3s 480us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 3s 480us/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 3s 497us/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 4s 523us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4946 - val_acc: 0.8020\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 4s 524us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 4s 528us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 3s 492us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 4s 608us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 4s 571us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 5s 763us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 5s 657us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 4s 567us/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 5s 685us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 4s 613us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4932 - val_acc: 0.8020\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 4s 634us/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 4s 545us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 4s 547us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 4s 509us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 4s 537us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 4s 524us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4948 - val_acc: 0.8020\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 4s 526us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4926 - val_acc: 0.8020\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 5s 645us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 5s 646us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 4s 512us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 4s 557us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4933 - val_acc: 0.8020\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 4s 621us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4935 - val_acc: 0.8020\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 4s 548us/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4927 - val_acc: 0.8020\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 4s 520us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 4s 585us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4924 - val_acc: 0.8020\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 3s 497us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4930 - val_acc: 0.8020\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 3s 475us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4926 - val_acc: 0.8020\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 3s 484us/sample - loss: 0.5006 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 4s 589us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 4s 583us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4933 - val_acc: 0.8020\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 3s 483us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 3s 482us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4908 - val_acc: 0.8020\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 3s 479us/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4933 - val_acc: 0.8020\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 3s 481us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 4s 504us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 4s 503us/sample - loss: 0.5028 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 3s 476us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 3s 483us/sample - loss: 0.5038 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 3s 480us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 3s 484us/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 3s 481us/sample - loss: 0.5028 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 3s 481us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 3s 485us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 3s 490us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 3s 485us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 3s 486us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5033 - acc: 0.7939 - val_loss: 0.4925 - val_acc: 0.8020\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 3s 488us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 3s 497us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 3s 490us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 4s 596us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 4s 567us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 4s 632us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 4s 569us/sample - loss: 0.5028 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 5s 653us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4929 - val_acc: 0.8020\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 4s 608us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4932 - val_acc: 0.8020\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 4s 632us/sample - loss: 0.5028 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 4s 539us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4938 - val_acc: 0.8020\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 4s 581us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 4s 583us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 4s 554us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4925 - val_acc: 0.8020\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 4s 584us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 4s 617us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 788us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4926 - val_acc: 0.8020\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 799us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4936 - val_acc: 0.8020\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 913us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4931 - val_acc: 0.8020\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca3c0adfd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df,diag_kind='kde',hue=\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding one more hidden layer to see if the accuracy increases in this context:\n",
    "\n",
    "model.add(tf.keras.layers.Dense(12,input_dim=8,activation='relu'))\n",
    "#Normalize the data \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(16,activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5137 - acc: 0.7927 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4930 - val_acc: 0.8020\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 839us/sample - loss: 0.5042 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 792us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 5s 681us/sample - loss: 0.5036 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 5s 695us/sample - loss: 0.5045 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 5s 670us/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4939 - val_acc: 0.8020\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 5s 674us/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 5s 737us/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.5042 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.80201s - loss: 0.5034 - acc: 0.7 - ETA: 0s - loss: 0.\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.5036 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5040 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4910 - val_acc: 0.8020\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5038 - acc: 0.7939 - val_loss: 0.4943 - val_acc: 0.8020: 1s - loss:\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 978us/sample - loss: 0.5033 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 960us/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4907 - val_acc: 0.8020\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 961us/sample - loss: 0.5033 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 954us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 931us/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 976us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5040 - acc: 0.7939 - val_loss: 0.4942 - val_acc: 0.8020\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 941us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 925us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4930 - val_acc: 0.8020\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5038 - acc: 0.7939 - val_loss: 0.4925 - val_acc: 0.8020\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 979us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4930 - val_acc: 0.8020\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5045 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5039 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5035 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4941 - val_acc: 0.8020 loss: 0.4943 - acc: 0.7 - ETA: 3s - loss: 0.4951 -\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 948us/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 899us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5039 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 930us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 976us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 936us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 910us/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 968us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 901us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5039 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 998us/sample - loss: 0.5036 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 951us/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4931 - val_acc: 0.8020\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 971us/sample - loss: 0.5022 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 961us/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 922us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4934 - val_acc: 0.8020\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 931us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 952us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 877us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 896us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 878us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 867us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 903us/sample - loss: 0.5030 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 920us/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4946 - val_acc: 0.8020\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 880us/sample - loss: 0.5039 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 875us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4929 - val_acc: 0.8020\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 838us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4910 - val_acc: 0.8020\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 5s 726us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 4s 626us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 4s 593us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 4s 601us/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 4s 594us/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 4s 602us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4933 - val_acc: 0.8020\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 4s 595us/sample - loss: 0.5025 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 4s 592us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 4s 595us/sample - loss: 0.5023 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 4s 594us/sample - loss: 0.5031 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 4s 635us/sample - loss: 0.5037 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 4s 597us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 5s 646us/sample - loss: 0.5026 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 822us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 790us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 5s 709us/sample - loss: 0.5029 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 5s 727us/sample - loss: 0.5032 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 5s 738us/sample - loss: 0.5033 - acc: 0.7939 - val_loss: 0.4927 - val_acc: 0.8020\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 5s 676us/sample - loss: 0.5034 - acc: 0.7939 - val_loss: 0.4908 - val_acc: 0.8020\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 5s 764us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 825us/sample - loss: 0.5027 - acc: 0.7939 - val_loss: 0.4927 - val_acc: 0.8020\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 5s 707us/sample - loss: 0.5024 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 5s 751us/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 5s 767us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 5s 737us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 813us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 807us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5019 - acc: 0.7939 - val_loss: 0.4910 - val_acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca45d38b38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to change the optimizer to Adam and trying to see how the model is peforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 6s 855us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5008 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 973us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5005 - acc: 0.7939 - val_loss: 0.4938 - val_acc: 0.8020\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 849us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4929 - val_acc: 0.8020\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 5s 659us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4911 - val_acc: 0.8020\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 4s 515us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 4s 519us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 4s 582us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 4s 537us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 5s 737us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 4s 552us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 4s 569us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 4s 580us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 4s 556us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 4s 516us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4924 - val_acc: 0.8020\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 4s 538us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 4s 576us/sample - loss: 0.5007 - acc: 0.7939 - val_loss: 0.4925 - val_acc: 0.8020\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 4s 600us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 4s 560us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 4s 521us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 4s 539us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 4s 575us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 4s 576us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 4s 535us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 4s 564us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 4s 597us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 4s 574us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 4s 563us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4927 - val_acc: 0.8020\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 4s 569us/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 872us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 4s 560us/sample - loss: 0.5001 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 4s 562us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 4s 579us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 4s 522us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 3s 482us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 3s 492us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 3s 479us/sample - loss: 0.5008 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 4s 502us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 3s 488us/sample - loss: 0.5004 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 3s 499us/sample - loss: 0.5018 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 3s 470us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 3s 489us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 4s 537us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 4s 503us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 3s 474us/sample - loss: 0.5008 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 3s 477us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4916 - val_acc: 0.8020\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 4s 526us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4929 - val_acc: 0.8020\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 3s 493us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 3s 481us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 3s 480us/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 3s 499us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4920 - val_acc: 0.8020\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 4s 524us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 4s 513us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 3s 486us/sample - loss: 0.5007 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 6s 850us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4910 - val_acc: 0.8020\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 4s 638us/sample - loss: 0.5009 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 4s 547us/sample - loss: 0.5004 - acc: 0.7939 - val_loss: 0.4919 - val_acc: 0.8020\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 4s 542us/sample - loss: 0.5003 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 3s 489us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 3s 487us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 4s 512us/sample - loss: 0.5006 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 3s 494us/sample - loss: 0.5008 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 3s 486us/sample - loss: 0.5001 - acc: 0.7939 - val_loss: 0.4929 - val_acc: 0.8020\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 3s 489us/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 4s 501us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 4s 529us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 4s 540us/sample - loss: 0.4996 - acc: 0.7939 - val_loss: 0.4924 - val_acc: 0.8020\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 4s 524us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 4s 514us/sample - loss: 0.5007 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 4s 583us/sample - loss: 0.4992 - acc: 0.7939 - val_loss: 0.4900 - val_acc: 0.8020\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 4s 524us/sample - loss: 0.5005 - acc: 0.7939 - val_loss: 0.4902 - val_acc: 0.8020\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 4s 542us/sample - loss: 0.4985 - acc: 0.7939 - val_loss: 0.4827 - val_acc: 0.8020\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 3s 498us/sample - loss: 0.5066 - acc: 0.7939 - val_loss: 0.4926 - val_acc: 0.8020\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 4s 535us/sample - loss: 0.5043 - acc: 0.7939 - val_loss: 0.4908 - val_acc: 0.8020\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 3s 498us/sample - loss: 0.5017 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 5s 644us/sample - loss: 0.5021 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.5003 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 4s 623us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 4s 512us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 3s 495us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4921 - val_acc: 0.8020\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 4s 588us/sample - loss: 0.5012 - acc: 0.7939 - val_loss: 0.4912 - val_acc: 0.8020\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 4s 582us/sample - loss: 0.5007 - acc: 0.7939 - val_loss: 0.4922 - val_acc: 0.8020\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 4s 626us/sample - loss: 0.5006 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 4s 593us/sample - loss: 0.5020 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 5s 660us/sample - loss: 0.5016 - acc: 0.7939 - val_loss: 0.4923 - val_acc: 0.8020\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 4s 539us/sample - loss: 0.5014 - acc: 0.7939 - val_loss: 0.4918 - val_acc: 0.8020\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 848us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.5006 - acc: 0.7939 - val_loss: 0.4917 - val_acc: 0.8020\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 4s 579us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 4s 615us/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 4s 598us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 4s 580us/sample - loss: 0.5013 - acc: 0.7939 - val_loss: 0.4915 - val_acc: 0.8020\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 4s 593us/sample - loss: 0.5015 - acc: 0.7939 - val_loss: 0.4914 - val_acc: 0.8020\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 4s 626us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4913 - val_acc: 0.8020\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 4s 590us/sample - loss: 0.5011 - acc: 0.7939 - val_loss: 0.4910 - val_acc: 0.8020\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 4s 625us/sample - loss: 0.5010 - acc: 0.7939 - val_loss: 0.4909 - val_acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca49539eb8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 44s 6ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.5001 - val_acc: 0.8020\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 41s 6ms/sample - loss: 0.5095 - acc: 0.7939 - val_loss: 0.4942 - val_acc: 0.8020\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 47s 7ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.4928 - val_acc: 0.8020\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.4948 - val_acc: 0.8020\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 38s 5ms/sample - loss: 0.5095 - acc: 0.7939 - val_loss: 0.4970 - val_acc: 0.8020\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5095 - acc: 0.7939 - val_loss: 0.5139 - val_acc: 0.8020\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 38s 5ms/sample - loss: 0.5095 - acc: 0.7939 - val_loss: 0.5265 - val_acc: 0.8020\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5094 - acc: 0.7939 - val_loss: 0.5421 - val_acc: 0.8020\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 39s 6ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5505 - val_acc: 0.8020\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 34s 5ms/sample - loss: 0.5094 - acc: 0.7939 - val_loss: 0.5380 - val_acc: 0.8020\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 37s 5ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.5459 - val_acc: 0.8020\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5471 - val_acc: 0.8020\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 39s 6ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5592 - val_acc: 0.8020\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 38s 5ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.5540 - val_acc: 0.8020\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 37s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5505 - val_acc: 0.8020\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5526 - val_acc: 0.8020\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.5496 - val_acc: 0.8020\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5490 - val_acc: 0.8020\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 40s 6ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5583 - val_acc: 0.8020\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5408 - val_acc: 0.8020\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5532 - val_acc: 0.8020\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.5498 - val_acc: 0.8020\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5463 - val_acc: 0.8020\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 45s 6ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5403 - val_acc: 0.8020\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5631 - val_acc: 0.8020\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 25s 4ms/sample - loss: 0.5093 - acc: 0.7939 - val_loss: 0.5561 - val_acc: 0.8020\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 26s 4ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5492 - val_acc: 0.8020\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 25s 4ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5430 - val_acc: 0.8020\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 25s 4ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5487 - val_acc: 0.8020\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 26s 4ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5498 - val_acc: 0.8020\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 25s 4ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5411 - val_acc: 0.8020\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 26s 4ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5469 - val_acc: 0.8020\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 26s 4ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5511 - val_acc: 0.8020\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5482 - val_acc: 0.8020\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 37s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5490 - val_acc: 0.8020\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 34s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5472 - val_acc: 0.8020\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 60s 9ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5455 - val_acc: 0.8020\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 37s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.5575 - val_acc: 0.8020\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5636 - val_acc: 0.8020\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 37s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5556 - val_acc: 0.8020\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 50s 7ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5496 - val_acc: 0.8020\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5407 - val_acc: 0.8020\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5601 - val_acc: 0.8020\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5491 - val_acc: 0.8020\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 40s 6ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5387 - val_acc: 0.8020\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5454 - val_acc: 0.8020\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5424 - val_acc: 0.8020\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 41s 6ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5463 - val_acc: 0.8020\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5594 - val_acc: 0.8020\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5521 - val_acc: 0.8020\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5092 - acc: 0.7939 - val_loss: 0.5538 - val_acc: 0.8020\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 43s 6ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5458 - val_acc: 0.8020\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5582 - val_acc: 0.8020\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 39s 6ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.5732 - val_acc: 0.8020\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 38s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5439 - val_acc: 0.8020\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.5589 - val_acc: 0.8020\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 40s 6ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5479 - val_acc: 0.8020\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 39s 6ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5593 - val_acc: 0.8020\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5425 - val_acc: 0.8020\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5649 - val_acc: 0.8020\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 35s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5541 - val_acc: 0.8020\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 34s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.5900 - val_acc: 0.8020\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5688 - val_acc: 0.8020\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5729 - val_acc: 0.8020\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5722 - val_acc: 0.8020\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5091 - acc: 0.7939 - val_loss: 0.5806 - val_acc: 0.8020\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5837 - val_acc: 0.8020\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5848 - val_acc: 0.8020\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.5997 - val_acc: 0.8020\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6048 - val_acc: 0.8020\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.5804 - val_acc: 0.8020\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6196 - val_acc: 0.5010\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6354 - val_acc: 0.5077\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6260 - val_acc: 0.5213\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6138 - val_acc: 0.5043\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6476 - val_acc: 0.5113\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6697 - val_acc: 0.5060\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6680 - val_acc: 0.5133\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6633 - val_acc: 0.5043\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6638 - val_acc: 0.5063\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6617 - val_acc: 0.5223\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6582 - val_acc: 0.5160\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6683 - val_acc: 0.5063\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 44s 6ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6660 - val_acc: 0.5020\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 36s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6775 - val_acc: 0.5077\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6611 - val_acc: 0.5140\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6676 - val_acc: 0.5087\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 34s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6619 - val_acc: 0.5047\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5088 - acc: 0.7939 - val_loss: 0.6498 - val_acc: 0.5083\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6720 - val_acc: 0.5053\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6792 - val_acc: 0.5097\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6571 - val_acc: 0.5153\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6578 - val_acc: 0.5213\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 29s 4ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6718 - val_acc: 0.5027\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6679 - val_acc: 0.5057\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6642 - val_acc: 0.5073\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 34s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6698 - val_acc: 0.5070\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5089 - acc: 0.7939 - val_loss: 0.6673 - val_acc: 0.4947\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6627 - val_acc: 0.5183\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 33s 5ms/sample - loss: 0.5090 - acc: 0.7939 - val_loss: 0.6637 - val_acc: 0.5147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca495699b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5808956 ],\n",
       "       [0.33103824],\n",
       "       [0.5808956 ],\n",
       "       ...,\n",
       "       [0.33103824],\n",
       "       [0.33103824],\n",
       "       [0.33103824]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(X_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5808956 , 0.33103824, 0.5808956 , ..., 0.33103824, 0.33103824,\n",
       "       0.33103824], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.514667\n",
      "Precision: 0.233622\n",
      "Recall: 0.636364\n",
      "F1 score: 0.341772\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, yhat_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1166 1240]\n",
      " [ 216  378]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
