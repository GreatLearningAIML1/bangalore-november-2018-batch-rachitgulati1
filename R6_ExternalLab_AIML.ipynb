{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 4us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 7s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX)\n",
    "print(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Comile the model ((We will learn about optimizers it in the next residency))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 3.0643 - acc: 0.0942 - val_loss: 12.7706 - val_acc: 0.1059\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 2.7795 - acc: 0.1266 - val_loss: 11.3018 - val_acc: 0.1136\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 2.5413 - acc: 0.1612 - val_loss: 9.9016 - val_acc: 0.1228\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 2.3421 - acc: 0.1982 - val_loss: 8.5796 - val_acc: 0.1368\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 2.1756 - acc: 0.2401 - val_loss: 7.3796 - val_acc: 0.1561\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 2.0364 - acc: 0.2806 - val_loss: 6.3426 - val_acc: 0.1739\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 1.9196 - acc: 0.3160 - val_loss: 5.4841 - val_acc: 0.1970\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.8210 - acc: 0.3469 - val_loss: 4.8022 - val_acc: 0.2210\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.7373 - acc: 0.3746 - val_loss: 4.2649 - val_acc: 0.2465\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.6654 - acc: 0.4008 - val_loss: 3.8390 - val_acc: 0.2735\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.6033 - acc: 0.4267 - val_loss: 3.4970 - val_acc: 0.3000\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.5490 - acc: 0.4512 - val_loss: 3.2186 - val_acc: 0.3240\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.5012 - acc: 0.4748 - val_loss: 2.9888 - val_acc: 0.3492\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.4587 - acc: 0.4954 - val_loss: 2.7969 - val_acc: 0.3740\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.4207 - acc: 0.5138 - val_loss: 2.6342 - val_acc: 0.3985\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.3864 - acc: 0.5304 - val_loss: 2.4946 - val_acc: 0.4188\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.3553 - acc: 0.5436 - val_loss: 2.3738 - val_acc: 0.4377\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.3268 - acc: 0.5552 - val_loss: 2.2679 - val_acc: 0.4565\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.3007 - acc: 0.5652 - val_loss: 2.1743 - val_acc: 0.4752\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.2766 - acc: 0.5739 - val_loss: 2.0912 - val_acc: 0.4919\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.2542 - acc: 0.5824 - val_loss: 2.0169 - val_acc: 0.5076\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.2333 - acc: 0.5896 - val_loss: 1.9501 - val_acc: 0.5211\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.2139 - acc: 0.5966 - val_loss: 1.8897 - val_acc: 0.5315\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1956 - acc: 0.6033 - val_loss: 1.8347 - val_acc: 0.5424\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1785 - acc: 0.6097 - val_loss: 1.7843 - val_acc: 0.5537\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.1623 - acc: 0.6149 - val_loss: 1.7379 - val_acc: 0.5624\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1470 - acc: 0.6197 - val_loss: 1.6952 - val_acc: 0.5706\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1326 - acc: 0.6243 - val_loss: 1.6556 - val_acc: 0.5786\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1189 - acc: 0.6286 - val_loss: 1.6187 - val_acc: 0.5871\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1059 - acc: 0.6330 - val_loss: 1.5843 - val_acc: 0.5940\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.0935 - acc: 0.6372 - val_loss: 1.5521 - val_acc: 0.5987\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.0817 - acc: 0.6412 - val_loss: 1.5219 - val_acc: 0.6045\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.0704 - acc: 0.6442 - val_loss: 1.4935 - val_acc: 0.6085\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.0597 - acc: 0.6473 - val_loss: 1.4667 - val_acc: 0.6119\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.0493 - acc: 0.6508 - val_loss: 1.4414 - val_acc: 0.6154\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 1.0395 - acc: 0.6538 - val_loss: 1.4175 - val_acc: 0.6184\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 1.0300 - acc: 0.6570 - val_loss: 1.3947 - val_acc: 0.6215\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.0209 - acc: 0.6597 - val_loss: 1.3732 - val_acc: 0.6249\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.0122 - acc: 0.6624 - val_loss: 1.3526 - val_acc: 0.6278\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.0038 - acc: 0.6647 - val_loss: 1.3330 - val_acc: 0.6314\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9957 - acc: 0.6672 - val_loss: 1.3142 - val_acc: 0.6346\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9879 - acc: 0.6696 - val_loss: 1.2963 - val_acc: 0.6371\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9803 - acc: 0.6716 - val_loss: 1.2792 - val_acc: 0.6390\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9731 - acc: 0.6741 - val_loss: 1.2627 - val_acc: 0.6413\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9660 - acc: 0.6763 - val_loss: 1.2470 - val_acc: 0.6436\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9593 - acc: 0.6783 - val_loss: 1.2319 - val_acc: 0.6456\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9527 - acc: 0.6801 - val_loss: 1.2174 - val_acc: 0.6472\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9463 - acc: 0.6817 - val_loss: 1.2034 - val_acc: 0.6488\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9402 - acc: 0.6834 - val_loss: 1.1900 - val_acc: 0.6517\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9342 - acc: 0.6849 - val_loss: 1.1770 - val_acc: 0.6536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1baa0ce8908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "#Already done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [],
   "source": [
    "#See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "learning_rate=0.001\n",
    "sgd=optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.9285 - acc: 0.6865 - val_loss: 1.1645 - val_acc: 0.6548\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9228 - acc: 0.6879 - val_loss: 1.1525 - val_acc: 0.6566\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9174 - acc: 0.6891 - val_loss: 1.1408 - val_acc: 0.6577\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9121 - acc: 0.6910 - val_loss: 1.1296 - val_acc: 0.6593\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.9070 - acc: 0.6924 - val_loss: 1.1187 - val_acc: 0.6612\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.9020 - acc: 0.6939 - val_loss: 1.1082 - val_acc: 0.6632\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.8971 - acc: 0.6953 - val_loss: 1.0981 - val_acc: 0.6652\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.8924 - acc: 0.6969 - val_loss: 1.0882 - val_acc: 0.6672\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.8878 - acc: 0.6980 - val_loss: 1.0787 - val_acc: 0.6688\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8833 - acc: 0.6994 - val_loss: 1.0694 - val_acc: 0.6708\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.8789 - acc: 0.7006 - val_loss: 1.0605 - val_acc: 0.6719\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.8747 - acc: 0.7018 - val_loss: 1.0518 - val_acc: 0.6731\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.8705 - acc: 0.7029 - val_loss: 1.0433 - val_acc: 0.6748\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.8665 - acc: 0.7037 - val_loss: 1.0351 - val_acc: 0.6760\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.8625 - acc: 0.7050 - val_loss: 1.0271 - val_acc: 0.6767\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.8587 - acc: 0.7061 - val_loss: 1.0194 - val_acc: 0.6785\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.8549 - acc: 0.7071 - val_loss: 1.0119 - val_acc: 0.6796\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8512 - acc: 0.7084 - val_loss: 1.0045 - val_acc: 0.6814\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8476 - acc: 0.7096 - val_loss: 0.9974 - val_acc: 0.6837\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8441 - acc: 0.7106 - val_loss: 0.9904 - val_acc: 0.6854\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8407 - acc: 0.7116 - val_loss: 0.9837 - val_acc: 0.6879\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8373 - acc: 0.7126 - val_loss: 0.9771 - val_acc: 0.6887\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.8340 - acc: 0.7136 - val_loss: 0.9707 - val_acc: 0.6900\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8308 - acc: 0.7148 - val_loss: 0.9645 - val_acc: 0.6904\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8277 - acc: 0.7160 - val_loss: 0.9584 - val_acc: 0.6909\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8246 - acc: 0.7169 - val_loss: 0.9524 - val_acc: 0.6921\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8216 - acc: 0.7181 - val_loss: 0.9466 - val_acc: 0.6929\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8186 - acc: 0.7192 - val_loss: 0.9410 - val_acc: 0.6948\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8157 - acc: 0.7201 - val_loss: 0.9355 - val_acc: 0.6966\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.8129 - acc: 0.7209 - val_loss: 0.9301 - val_acc: 0.6975\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8101 - acc: 0.7222 - val_loss: 0.9249 - val_acc: 0.6985\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8074 - acc: 0.7232 - val_loss: 0.9197 - val_acc: 0.6998\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8047 - acc: 0.7240 - val_loss: 0.9147 - val_acc: 0.7012\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.8021 - acc: 0.7247 - val_loss: 0.9098 - val_acc: 0.7018\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7995 - acc: 0.7255 - val_loss: 0.9051 - val_acc: 0.7030\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7969 - acc: 0.7266 - val_loss: 0.9004 - val_acc: 0.7038\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.7945 - acc: 0.7274 - val_loss: 0.8958 - val_acc: 0.7050\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.7920 - acc: 0.7283 - val_loss: 0.8914 - val_acc: 0.7070\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.7896 - acc: 0.7291 - val_loss: 0.8870 - val_acc: 0.7074\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7873 - acc: 0.7298 - val_loss: 0.8828 - val_acc: 0.7083\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.7850 - acc: 0.7305 - val_loss: 0.8786 - val_acc: 0.7099\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7827 - acc: 0.7313 - val_loss: 0.8745 - val_acc: 0.7109\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7804 - acc: 0.7321 - val_loss: 0.8705 - val_acc: 0.7117\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7782 - acc: 0.7328 - val_loss: 0.8666 - val_acc: 0.7127\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7761 - acc: 0.7336 - val_loss: 0.8628 - val_acc: 0.7140\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7740 - acc: 0.7343 - val_loss: 0.8591 - val_acc: 0.7147\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7719 - acc: 0.7351 - val_loss: 0.8554 - val_acc: 0.7160\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7698 - acc: 0.7358 - val_loss: 0.8518 - val_acc: 0.7165\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7678 - acc: 0.7363 - val_loss: 0.8483 - val_acc: 0.7176\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7658 - acc: 0.7371 - val_loss: 0.8449 - val_acc: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1baa14e7898>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "learning_rate=0.03\n",
    "sgd=optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 2.9341 - acc: 0.1111 - val_loss: 2.8868 - val_acc: 0.1138\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.8881 - acc: 0.1155 - val_loss: 2.8433 - val_acc: 0.1138\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.8455 - acc: 0.1205 - val_loss: 2.8032 - val_acc: 0.1152\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.8060 - acc: 0.1264 - val_loss: 2.7660 - val_acc: 0.1163\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.7693 - acc: 0.1310 - val_loss: 2.7316 - val_acc: 0.1176\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.7354 - acc: 0.1358 - val_loss: 2.6997 - val_acc: 0.1192\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.7039 - acc: 0.1399 - val_loss: 2.6703 - val_acc: 0.1202\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.6748 - acc: 0.1438 - val_loss: 2.6429 - val_acc: 0.1208\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.6477 - acc: 0.1474 - val_loss: 2.6176 - val_acc: 0.1217\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.6226 - acc: 0.1503 - val_loss: 2.5941 - val_acc: 0.1228\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.5993 - acc: 0.1525 - val_loss: 2.5723 - val_acc: 0.1242\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.5776 - acc: 0.1544 - val_loss: 2.5520 - val_acc: 0.1253\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 2.5574 - acc: 0.1561 - val_loss: 2.5331 - val_acc: 0.1266\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.5386 - acc: 0.1574 - val_loss: 2.5155 - val_acc: 0.1271\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.5211 - acc: 0.1589 - val_loss: 2.4991 - val_acc: 0.1276\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 2.5047 - acc: 0.1603 - val_loss: 2.4837 - val_acc: 0.1285\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 2.4894 - acc: 0.1614 - val_loss: 2.4694 - val_acc: 0.1298\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 2.4751 - acc: 0.1621 - val_loss: 2.4560 - val_acc: 0.1307\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.4617 - acc: 0.1628 - val_loss: 2.4434 - val_acc: 0.1312\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.4492 - acc: 0.1634 - val_loss: 2.4316 - val_acc: 0.1319\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.4374 - acc: 0.1641 - val_loss: 2.4206 - val_acc: 0.1332\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.4263 - acc: 0.1645 - val_loss: 2.4101 - val_acc: 0.1347\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 2.4159 - acc: 0.1650 - val_loss: 2.4003 - val_acc: 0.1352\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 2.4061 - acc: 0.1657 - val_loss: 2.3911 - val_acc: 0.1360\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.3968 - acc: 0.1662 - val_loss: 2.3824 - val_acc: 0.1373\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.3881 - acc: 0.1667 - val_loss: 2.3742 - val_acc: 0.1379\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.3799 - acc: 0.1670 - val_loss: 2.3664 - val_acc: 0.1384\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.3721 - acc: 0.1672 - val_loss: 2.3590 - val_acc: 0.1393\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.3647 - acc: 0.1675 - val_loss: 2.3521 - val_acc: 0.1403\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.3577 - acc: 0.1678 - val_loss: 2.3455 - val_acc: 0.1413\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 2.3511 - acc: 0.1681 - val_loss: 2.3392 - val_acc: 0.1432\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 2.3448 - acc: 0.1682 - val_loss: 2.3332 - val_acc: 0.1443\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 2.3388 - acc: 0.1685 - val_loss: 2.3276 - val_acc: 0.1468\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 2.3332 - acc: 0.1690 - val_loss: 2.3222 - val_acc: 0.1497\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 2.3278 - acc: 0.1693 - val_loss: 2.3170 - val_acc: 0.1519\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 2.3226 - acc: 0.1696 - val_loss: 2.3121 - val_acc: 0.1542\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.3177 - acc: 0.1698 - val_loss: 2.3075 - val_acc: 0.1569\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.3130 - acc: 0.1700 - val_loss: 2.3030 - val_acc: 0.1610\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 2.3085 - acc: 0.1701 - val_loss: 2.2987 - val_acc: 0.1637\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 2.3043 - acc: 0.1704 - val_loss: 2.2946 - val_acc: 0.1663\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.3002 - acc: 0.1708 - val_loss: 2.2907 - val_acc: 0.1684\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.2963 - acc: 0.1710 - val_loss: 2.2869 - val_acc: 0.1714\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.2925 - acc: 0.1713 - val_loss: 2.2833 - val_acc: 0.1737\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.2889 - acc: 0.1717 - val_loss: 2.2798 - val_acc: 0.1767\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.2854 - acc: 0.1720 - val_loss: 2.2765 - val_acc: 0.1788\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.2821 - acc: 0.1729 - val_loss: 2.2733 - val_acc: 0.1818\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 2.2789 - acc: 0.1737 - val_loss: 2.2702 - val_acc: 0.1841\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 2.2758 - acc: 0.1748 - val_loss: 2.2672 - val_acc: 0.1865\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.2728 - acc: 0.1756 - val_loss: 2.2643 - val_acc: 0.1893\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 2.2699 - acc: 0.1768 - val_loss: 2.2615 - val_acc: 0.1918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ba80262518>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
